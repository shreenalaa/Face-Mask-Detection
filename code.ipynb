{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the Dependencies** ðŸ’¦ðŸ’™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image  as img \n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Data** ðŸ’¦ðŸ’™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_mask = os.listdir('data/with_mask')\n",
    "print(with_mask[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_mask = os.listdir('data/without_mask')\n",
    "print(without_mask[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(with_mask))\n",
    "print (len(without_mask))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating Labels** ðŸ’¦ðŸ’™\n",
    "- with mask >> 1 \n",
    "- without mask >> 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_mask_labels = [1]*3725\n",
    "without_mask_labels = [0]*3828\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(with_mask_labels[0:5])\n",
    "print(without_mask_labels[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine 2 sets \n",
    "\n",
    "labels = with_mask_labels + without_mask_labels \n",
    "print(len(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Displaying Images** ðŸ’¦ðŸ’™\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = img.imread('data/with_mask/with_mask_1.jpg')\n",
    "img_plot = plt.imshow(image)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = img.imread('data/without_mask/without_mask_1000.jpg')\n",
    "img_plot = plt.imshow(image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image Processing**ðŸ’¦ðŸ’™\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Resize the Images\n",
    "2. Convert the images to numpy arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert images to numpy arrays+\n",
    "\n",
    "with_mask_path = 'data/with_mask/'\n",
    "\n",
    "data = []\n",
    "\n",
    "for img_file in with_mask:\n",
    "\n",
    "  image = Image.open(with_mask_path + img_file)\n",
    "  image = image.resize((128,128))\n",
    "  image = image.convert('RGB')\n",
    "  image = np.array(image)\n",
    "  data.append(image)\n",
    "\n",
    "\n",
    "\n",
    "without_mask_path = 'data/without_mask/'\n",
    "\n",
    "\n",
    "for img_file in without_mask:\n",
    "\n",
    "  image = Image.open(without_mask_path + img_file)\n",
    "  image = image.resize((128,128))\n",
    "  image = image.convert('RGB')\n",
    "  image = np.array(image)\n",
    "  data.append(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting image list and label list to numpy arrays\n",
    "\n",
    "\n",
    "X = np.array(data)\n",
    "Y = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Data to train and test** ðŸ’¦ðŸ’™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling The Data** ðŸ’¦ðŸ’™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train/255\n",
    "\n",
    "X_test_scaled = X_test/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building a Convolutional Neural Networks (CNN)** ðŸ’¦ðŸ’™\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_classes = 2  # binary classification , The network will output two probabilities representing each class.\n",
    "\n",
    "model = keras.Sequential() # This model is a linear stack of layers where each layer has one input tensor and one output tensor.\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(128,128,3)))\n",
    "# Conv2D(32): This adds a 2D convolutional layer with 32 filters (also known as kernels).\n",
    "# kernel_size=(3,3): The size of each filter is 3x3 pixels.\n",
    "# activation='relu': The Rectified Linear Unit (ReLU) activation function is applied, which introduces non-linearity by setting negative values to 0 and keeping positive values as they are.\n",
    "# input_shape=(128,128,3): This specifies the shape of the input data, which in this case is a 128x128 image with 3 channels (likely RGB).\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "# MaxPooling2D(pool_size=(2,2)): This layer downsamples the input by taking the maximum value from each 2x2 block of pixels, \n",
    "# effectively reducing the spatial dimensions (width and height) by half. \n",
    "# This helps reduce computational cost and also prevents overfitting by making the model more invariant to small shifts in the input.\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu')) #Second Convolutional Layer\n",
    "\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2))) #Second Max Pooling Layer\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "# Flatten(): This layer flattens the multi-dimensional output from the previous convolutional and pooling layers into a 1D vector.\n",
    "# This is necessary before feeding the data into a fully connected layer (Dense layer).\n",
    "\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "# Dense(128): This adds a fully connected (dense) layer with 128 neurons.\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "# Dropout(0.5): Dropout is a regularization technique where 50% of the neurons in this layer are randomly ignored (dropped) during training to prevent overfitting. \n",
    "# This helps make the model more robust by ensuring it doesn't rely too heavily on any one neuron.\n",
    "model.add(keras.layers.Dense(64, activation='relu'))  #Second Fully Connected (Dense) Layer\n",
    "model.add(keras.layers.Dropout(0.5)) #Second Dropout Layer\n",
    "\n",
    "\n",
    "model.add(keras.layers.Dense(num_of_classes, activation='sigmoid')) #Output Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the neural network\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the neural network\n",
    "history = model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation** ðŸ’¦ðŸ’™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test_scaled, Y_test)\n",
    "print('Test Accuracy =', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = history\n",
    "\n",
    "# plot the loss value\n",
    "plt.plot(h.history['loss'], label='train loss')\n",
    "plt.plot(h.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot the accuracy value\n",
    "plt.plot(h.history['acc'], label='train accuracy')\n",
    "plt.plot(h.history['val_acc'], label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictive System** ðŸ’¦ðŸ’™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_path = input('Path of the image to be predicted: ')\n",
    "\n",
    "input_image = cv2.imread(input_image_path)\n",
    "\n",
    "# Check if the image was loaded successfully\n",
    "if input_image is None:\n",
    "    print(\"Error: Image not found or unable to load.\")\n",
    "else:\n",
    "    # Display the image in a window named 'Input Image'\n",
    "    cv2.imshow('Input Image', input_image)\n",
    "\n",
    "    # Wait until a key is pressed\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    # Destroy all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Resize the image to the input size expected by the model\n",
    "    input_image_resized = cv2.resize(input_image, (128, 128))\n",
    "\n",
    "    # Normalize the image\n",
    "    input_image_scaled = input_image_resized / 255.0\n",
    "\n",
    "    # Reshape the image to fit the model input\n",
    "    input_image_reshaped = np.reshape(input_image_scaled, [1, 128, 128, 3])\n",
    "\n",
    "    # Predict using the model\n",
    "    input_prediction = model.predict(input_image_reshaped)\n",
    "\n",
    "    # Print the prediction probabilities\n",
    "    print(\"Prediction probabilities:\", input_prediction)\n",
    "\n",
    "    # Get the predicted class\n",
    "    input_pred_label = np.argmax(input_prediction)\n",
    "\n",
    "    # Print the predicted label\n",
    "    print(\"Predicted label:\", input_pred_label)\n",
    "\n",
    "    # Interpret the result\n",
    "    if input_pred_label == 1:\n",
    "        print('The person in the image is wearing a mask')\n",
    "    else:\n",
    "        print('The person in the image is not wearing a mask')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
